{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1342b37a-adce-4068-9c65-50e70c58f1a0",
   "metadata": {},
   "source": [
    "> Author: @ DP \n",
    ">> edited by: @DP 4/29/22 version 0.3\n",
    "\n",
    "------\n",
    "\n",
    ">#### To Do ####\n",
    "\n",
    ">#### Completed Activity ####\n",
    "\n",
    "- [x] Add code to grab the IDs from the .fastq files in example data \n",
    "- [x] Modify a regex of sample ID check for sample mismatch\n",
    "- [x] Reviewd the code using csv and fatq files.\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "## AMD ID Quality Check ##\n",
    "\n",
    "### Background: ### \n",
    "\n",
    "A standardized sample naming schema is used to capture all associated meta-data prior to sequencing. Briefly, the `AMD ID` consist of 20 characters that capture information like collection year, geographical and treatment information, sample type and molecular markers included for each sample. \n",
    "\n",
    "Capturing this information at the pre-processing stage reduces the need to have multiple documents with this information, removing potential for mislabeling or tracking errors, and provides the bioiformatics team  with sufficient information to perform subsequent analysis and standardize analysis pipelines, including submission of data to NCBI. \n",
    "\n",
    "#### AMD ID Description #### \n",
    "\n",
    "* The AMD ID Key:  `<year> <country> <state/site> <day of failure> <treatment> <sample_id> <genus spp> <sample type> <mol marker bit code> <# sample processed>`. \n",
    "* Any missing meta data is replaced with an `x` _lower case_ strings for each character position. \n",
    "\n",
    "Example:\n",
    "- `Individual` sequenced sample ID: `17GNDo00F0001PfF1290` = `<2017> <Guinea> <Dorota> <Day0> <AS+AQ> <0001> <P.falciparum> <FilterBloodSpot> <k13-crt-mdr-dhfr-dhps-cytB-cpmp-pfs47> <0>` \n",
    "\n",
    "                       \n",
    "- `Pooled` sequenced sample ID: `17GNDo00x001p10F1290` = `<2017> <Guinea> <Dorota> <Day0> <missing info> <001> <Pooled Samples> <Samples in Pool> <FilterBloodSpot> <k13-crt-mdr-dhfr-dhps-cytB-cpmp-pfs47> <0>`\n",
    "       \n",
    "NOTE: If information is not availble (na), **x** is used for each character position. For example, in the pooled samples Treatment has (2) character spaces, represented as a two digit integer code. This is replaced with (2) **xx** since its a pool of samples that have possibly different Treatment information. Moreover, for pooled samples, **Sample ID** is replaced with **three digit number + the letter p** (for pooled), and **Genus** is replaced with **total number of SamplesInPool** as a (2) digit number. \n",
    "\n",
    "Please see presentation at `MaRS/Geneious_workflow/01_sample_ID_QC/files/AMD_ID_create_key.pptx` for more descriptive information. The AMD ID can be generated using the `MaRS/Geneious_workflow/01_sample_ID_QC/files/AMD_ID_create_template.xlsx`. \n",
    "\n",
    "     \n",
    "### Code information ###\n",
    "\n",
    "This code checks whether the `AMD ID` is the correct length and contains all the required elements described above. \n",
    "\n",
    "### Required packages ###\n",
    "- [Pandas](https://pandas.pydata.org/) \n",
    "- [os](https://docs.python.org/3/library/os.html)\n",
    "- [re](https://docs.python.org/3/library/re.html) \n",
    "- [tabulate](https://pypi.org/project/tabulate/)\n",
    "\n",
    "### Inputs ###\n",
    "- .csv file that includes the AMD_IDs or fastqfile names in AMD_ID format\n",
    "\n",
    "### Outputs ### \n",
    "- List of incorrect AMD_IDs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bcb5ad-6a9e-42f5-ad49-31b0304fdf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d78908d8-a645-4294-a4f6-cb9d39ad14ea",
   "metadata": {},
   "source": [
    "### Below code takes a user input for files and directory. It checks if input is fastq files or csv file with sample ID. \n",
    "\n",
    "**Note:** Use .csv file as input when it requires to QC the files before the sequancing otherwise use the fastq files from a sample directory for QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2daae03-8eb2-4a1c-8f5c-6ebf9a2bebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specify the file type: \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "csv or raw_fastq csv\n",
      "Please enter a valid file path to a csv:  /Users/dhruviben/Desktop/PARMA-SOP/test_script.csv\n"
     ]
    }
   ],
   "source": [
    "## Import dependencies ## \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tabulate\n",
    "\n",
    "\n",
    "print(\"specify the file type: \\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        file_type = input(\"csv or raw_fastq\")\n",
    "        \n",
    "        if file_type == \"csv\":                                                                       # If the file is csv (only ids)\n",
    "            Sample_filepath  = input(\"Please enter a valid file path to a csv: \")                    # Ask user input for the path of .csv file with sample IDs\n",
    "\n",
    "            while not os.path.isfile(Sample_filepath):\n",
    "                    print(\"Error: That is not a valid file, try again...\")                            # Error if file is not found\n",
    "                    Sample_filepath = input(\"Please enter a valid file path to a csv: \")              # If error, enter again the file path\n",
    "                    \n",
    "            Sample_file = pd.read_csv(Sample_filepath)                                                # Read a csv file using pandas csv function\n",
    "            \n",
    "            break\n",
    "            \n",
    "                                                                                                      # If using a fastq files from a specific directory\n",
    "        if file_type == \"raw_fastq\":\n",
    "            \n",
    "            inputdirectory = input(\"Enter the full path of the folder containing your files: \")       # input directory name  \n",
    "            \n",
    "            \n",
    "            while not os.path.isdir(inputdirectory):\n",
    "                    print(\"Error: That is not a valid Folder, try again...\")                                             # Error if folder is not found\n",
    "                    inputdirectory = input(\"Please type in the full path of the folder containing your files:   \")       # If error, enter again the file path          \n",
    "            \n",
    "            inputfile_extensions = input(\"Please type in the file extension of your files: \")                            # input extension of files (gz or fastq.gz)\n",
    "            files =os.path.join(inputdirectory, \"*.\"+inputfile_extensions)                                               # join the path of dir and extension of file\n",
    "           \n",
    "            my_file = [f for f in glob.glob(files)]                                                                      # use glob functio to list the files\n",
    "            \n",
    "            clean_filenames = [doc_name.split(\"/\")[-1].split(\"_\")[0] for doc_name in my_file]                             \n",
    "            Sample_file = pd.DataFrame(clean_filenames, columns=[\"AMD_ID\"])                                              # add column name to data frame called AMD_ID\n",
    "            Sample_file = Sample_file.drop_duplicates()                                                                  # drop duplicates from list\n",
    "            print(Sample_file)\n",
    "            break        \n",
    "        \n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid file type.\")      \n",
    "   \n",
    "\n",
    "    except ValueError:\n",
    "        \n",
    "        print(\"provide a correct file type...\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c25347-331f-4487-aab1-e564cfbb72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creat a empty list for AMD_IDs \n",
    "\n",
    "Sample_no_match = []        # All the Ids with no match will be saved in list\n",
    "Sample_with_match = []      # all the ID which has length  20 will be saved in list\n",
    " \n",
    "## First part is to check if Sample ID has length 20 or not\n",
    "\n",
    "Sample_name = Sample_file.rename(columns={'Sample':\"Sample_ID\", 'AMD_ID': \"Sample_ID\",'AMD ID (Pooled)': \"Sample_ID\", 'Document Name': \"Sample_ID\"})      # rename column name to Sample_ID as differant files migth have diffenrt column name.\n",
    "  \n",
    "SampleID_df = Sample_name[['Sample_ID']]                       # creat a dataframe using the column Sample_ID \n",
    "\n",
    "#remove US conrtols to avoid any errors in sample ID\n",
    "\n",
    "SampleID_df = SampleID_df[SampleID_df['Sample_ID'].str.contains(\"USxxxx\") == False]\n",
    "\n",
    "\n",
    "for rows in SampleID_df.index:                                 # run a for loop on each rows\n",
    "    \n",
    "    sample_name =SampleID_df['Sample_ID'][rows].split('/n')    # split rows by newline\n",
    "    for each_ID in sample_name:\n",
    "        if len(each_ID) == 20 :                                # if length is 20, save the samples in Sample_with_match list\n",
    "            Sample_with_match.append(each_ID) \n",
    "        else: \n",
    "            Sample_no_match.append(each_ID)                    # if length is not 20 then save the results in Sample_no_match list. \n",
    "            #print(each_ID,\"has length\", int(len(each_ID)))     # print the sample ID with its length if less than 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c7784f-7ec0-426d-b770-16003409b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2nd part is to check all ID with length 20, if it matches with AMD ID information regular expression as shown in discription at begining.\n",
    "\n",
    "for each_file  in Sample_with_match:                                     # Run a for loop for each file in Sample_with_match list\n",
    "    \n",
    "    AMD_ID =('([0-9]{2})([A-Zx]{2})([A-Za-z]{2})([0-9x]{2})([A-Yx]{1})([0-9]{3})(([0-9]{1})|([p]{1}))(([0-9]{2})|([Pf]{2}))([A-Zx]{1})([0-9x]{3})([0-9]{1})')\n",
    "             \n",
    "                                                                         # split AMD ID by its information using regular expression\n",
    "   \n",
    "    AMD_group = re.match(AMD_ID,each_file)                               # match each ID with pattern\n",
    "    \n",
    "    if AMD_group is None :                                               # if match does not found\n",
    "            \n",
    "        Sample_no_match.append(each_file)                                # append the ID to list\n",
    "        #print(each_file, \"is not maching with ID\")\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        pass                                                             # if ID match with regex, pass\n",
    "#print(Sample_with_match)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a48978-87bc-409a-ad6a-107cbb637f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 out of 23 samples did not match with AMD_ID\n",
      "\n",
      "Here is the list of samples that did not match\n",
      "20MDAn00X002p5F0671\n",
      "20MDAn00X00205F0671\n",
      "19ANBe00A0009PfFxxx\n",
      "19ANBe00A0010PfFxxx\n",
      "NTC-DFR\n",
      "17GNDo00F0001PfF129\n",
      "17GNDo00F0001PfF12911\n",
      "17GNDo00F0001PfF1\n",
      "17GNDo0F0001PfF1291\n",
      "191NBe00A0026PfFxxx0\n",
      "19ANBe00A0031P1Fxxx0\n"
     ]
    }
   ],
   "source": [
    "## lastly, print All the IDs without match so that user can review them and make a corrction before further processing.\n",
    "print(len(Sample_no_match), \"out of\", len(SampleID_df),\"samples did not match with AMD_ID\")         # print the total number of samples that did not match \n",
    "\n",
    "\n",
    "if len(Sample_no_match) == 0:\n",
    "        print(\"you are good to proceed with analysis: All the samples pass through QC test\")\n",
    "else :\n",
    "    print(\"\\nHere is the list of samples that did not match\")\n",
    "    \n",
    "ID_No_match = \"\\n\".join ([str(ID) for ID in Sample_no_match if len(Sample_no_match) != 0 ])         #  print the list of IDs that did not match \n",
    "print(ID_No_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0885b3c0-3638-488a-ba9a-5852d54fe14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| name                  |   length_of_sample_ID |   year | country   | Site   | Treatment_Day   | Treatment   | ID   | Genus_Pooled   | Type   | GenemarkerCode   | Repeat   |\n",
      "+=======================+=======================+========+===========+========+=================+=============+======+================+========+==================+==========+\n",
      "| 20MDAn00X002p5F0671   |                    19 |     20 | MD        | An     | 00              | X           | 002p | 5F             | 0      | 671              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 20MDAn00X00205F0671   |                    19 |     20 | MD        | An     | 00              | X           | 0020 | 5F             | 0      | 671              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 19ANBe00A0009PfFxxx   |                    19 |     19 | AN        | Be     | 00              | A           | 0009 | Pf             | F      | xxx              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 19ANBe00A0010PfFxxx   |                    19 |     19 | AN        | Be     | 00              | A           | 0010 | Pf             | F      | xxx              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| NTC-DFR               |                     7 |        |           |        |                 |             |      |                |        |                  |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 17GNDo00F0001PfF129   |                    19 |     17 | GN        | Do     | 00              | F           | 0001 | Pf             | F      | 129              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 17GNDo00F0001PfF12911 |                    21 |     17 | GN        | Do     | 00              | F           | 0001 | Pf             | F      | 129              | 11       |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 17GNDo00F0001PfF1     |                    17 |     17 | GN        | Do     | 00              | F           | 0001 | Pf             | F      | 1                |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 17GNDo0F0001PfF1291   |                    19 |     17 | GN        | Do     | 0F              | 0           | 001P | fF             | 1      | 291              |          |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 191NBe00A0026PfFxxx0  |                    20 |     19 | 1N        | Be     | 00              | A           | 0026 | Pf             | F      | xxx              | 0        |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n",
      "| 19ANBe00A0031P1Fxxx0  |                    20 |     19 | AN        | Be     | 00              | A           | 0031 | P1             | F      | xxx              | 0        |\n",
      "+-----------------------+-----------------------+--------+-----------+--------+-----------------+-------------+------+----------------+--------+------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# This part of code runs through the samples_no_match list and creats a table with key. Then user can identyfy where the key does not match visually from the table.\n",
    "\n",
    "data_regex_QC = []                               \n",
    "\n",
    "\n",
    "# Loop through the Sample id with no match list, split the ID by key using regex and creat dictionary .\n",
    "\n",
    "for id in Sample_no_match:\n",
    "    if len(id) >= 15:\n",
    "        match = re.match(r\"(?P<year>\\w{2})(?P<country>\\w{2})(?P<Site>\\w{2})(?P<Treatment_Day>\\w{2})(?P<Treatment>\\w{1})(?P<ID>\\w{4})(?P<Genus_Pooled>\\w{,2})(?P<Type>\\w{,1})(?P<GenemarkerCode>\\w{,3})(?P<Repeat>\\w{0,})\", id)\n",
    "        dic = match.groupdict()\n",
    "        Dict_QC_re ={\"name\": id,\"length_of_sample_ID\" : len(id)}              # append the two keys to dict for Sample name and its length\n",
    "        Dict_QC_re.update(dic)                                                # update a dict with new key value pair i.e name and length\n",
    "        data_regex_QC.append(Dict_QC_re)     \n",
    "    elif len(id) < 15:\n",
    "        Dict_QC_re ={\"name\": id,\"length_of_sample_ID\" : len(id)}              # append the two keys to dict for Sample name and its length\n",
    "        data_regex_QC.append(Dict_QC_re)     \n",
    "                                   \n",
    "        \n",
    "if len(data_regex_QC) != 0:                                            # If length of list is not 0; \n",
    "    header = data_regex_QC[0].keys()                                   # header = keys of dict\n",
    "    rows = [x.values() for x in data_regex_QC]                         # rows will be value of dict\n",
    "    print (tabulate.tabulate(rows, header, tablefmt=\"grid\"))           # use tabulate module to creat a table   \n",
    "\n",
    "else:\n",
    "    print('\\n',\"All the samples are matching with AMD_ID\",\"\\n\", \"No errors found in samples\")        # If all the IDs matched with AMD id no table will be created. \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39797862-bfeb-40c3-92dd-5d01d84e2151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
