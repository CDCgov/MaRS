{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201be23-fba4-49a2-9815-ddacef7338ca",
   "metadata": {},
   "source": [
    "### REQUIRED SET UP\n",
    "If you opened this not using a virtual env set up, please read [Virtual Env for python notebooks](https://www.zainrizvi.io/blog/jupyter-notebooks-best-practices-use-virtual-environments/) and restart. Thank you!\n",
    "\n",
    "### Background \n",
    "\n",
    "[NCBI MaRS Bioproject](https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA428490) is used to submit raw fastq files along with associated meta data as soon as possible. NCBI requires that associated meta data (attributes) is submitted with each fastq record. \n",
    "\n",
    "### Code information \n",
    "\n",
    "The code block below links the sample specific meta data (ex. CSID, EPI_ID, Molecular Classification, Day of Treatment, Treatment) to the AMD ID generated by the NGS lab team (AMD ID = name of each fastq file). For more information about the AMD ID, please refer to the MS Teams channel Domestic Surveillance > Files > Sample Naming.  \n",
    "\n",
    "### Required dependencies \n",
    "\n",
    "\n",
    " - [pandas](https://pandas.pydata.org)\n",
    " - [numpy](https://numpy.org)\n",
    " - [glob](https://docs.python.org/3/library/glob.html)\n",
    " - [skimpy](https://pypi.org/project/skimpy/) \n",
    " - [openpyxl](https://openpyxl.readthedocs.io/en/stable/) \n",
    " \n",
    "```python\n",
    "python3 -m pip install --upgrade pip  # upgrade pip \n",
    "python3 -m pip install module_name    # install modules via terminal in current virtual env; if you run into issues, install it system wide. \n",
    "\n",
    "```\n",
    " \n",
    "### Inputs\n",
    "\n",
    "Under one directory\n",
    " - Raw fastq paired files\n",
    "     - Make sure to rename the directory to the specific country (ex. raw reads > Guinea) \n",
    " - Excel files with metadata information (this is provided by the NGS lab and Microsatellites Team) \n",
    "\n",
    "\n",
    " ### Output\n",
    " - csv file with all metadata linked with the AMD ID to be used during the NCBI SRA submission \n",
    "  \n",
    " Note: This code is written for Guinea Paired samples. Please modify the filepaths, filenames, etc for another use case (e.g., country). \n",
    " \n",
    " #### TODO: \n",
    " \n",
    "  #### Activity Name\n",
    " - [ ] Add QC checks (ex. count of ID and elements match) and random cross-match & visual inspect @Dhruvi & Je-Hoon 03-31-2022 \n",
    " - [ ] Review with @ Eldin \n",
    " - [ ] Talk to Lab and NMS team (@ Samaly) and ensure excel format is standardized including naming of files, tabs, etc @Dhruvi 04-01-2022 \n",
    "    \n",
    " #### Completed Activity âœ“\n",
    " - [x] Updated readme, code to make it more explicit and detailed comments @ET 03-31-2022 \n",
    " - [x] Seperated code based on processes and added basic QC sections @ET 03-31-2022 \n",
    " - [x] placeholder \n",
    "\n",
    " #### Task \n",
    " _Template_ \n",
    " \n",
    " - [ ] Task title ~3d #type @name yyyy-mm-dd\n",
    "    - [ ] Sub-task description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d782de83-a16e-4373-ac88-77704b80aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up saved variables; clean slate ## \n",
    "#dir()      # check saved variables \n",
    "#%reset    # this cleares saved variables; use only if there are too many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b3fd93a9-7bf0-4a5b-a8a8-385c7b213b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many filename records are unique: 76\n"
     ]
    }
   ],
   "source": [
    "## Import dependencies ## \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimpy import skim\n",
    "\n",
    "## Get fastq filenames ## \n",
    "\n",
    "my_file = [f for f in glob.glob(\"Guinea/*.fastq.gz\")]                  # use glob to save the files names to my_file variable (var)   \n",
    "clean_filenames = []                                                   # create an empty list called fastq_raw var \n",
    "\n",
    "## Cleaning of filenames ## \n",
    "\n",
    "for doc_name in my_file:                                               # loop through my_file \n",
    "    new_doc_name = doc_name.replace('Guinea/',\"\")                      # remove \"Guinea/\" from filename and save in new_doc_name var \n",
    "    clean_filenames.append(new_doc_name.split(\"_\")[0])                 # split file name by underscore \"_\" and keep 20 digit AMD ID and save as clean_filenames var \n",
    "\n",
    "## Create clean dataframe with cleaned filenames ## \n",
    "\n",
    "clean_df = pd.DataFrame(clean_filenames, columns=[\"AMD_ID\"])           # add column name to data frame called AMD_ID\n",
    "clean_df = clean_df.drop_duplicates()                                  # drop duplicate records since each fastq record is paired (fq1 and fq2) \n",
    "\n",
    "## Check how many unique records ## \n",
    "\n",
    "clean_df_w_controls = clean_df.AMD_ID.nunique()                        # count number of unique elements \n",
    "print('This many filename records are unique:', clean_df_w_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "bee2ebb6-c1e0-4af2-91ca-acab8e810686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 control or US domestic samples were removed, leaving now: 72 records\n"
     ]
    }
   ],
   "source": [
    "## Remove US or control strains from dataframe ## \n",
    "\n",
    "discard = [\"21US\"]                                                     # provide specific string pattern and save as discard var; discard all domestic samples or control strains \n",
    "\n",
    "clean_df = clean_df[~clean_df.AMD_ID.str.contains('|'.join(discard))]  # test if string pattern or regex is conatined within a string and drop the rows\n",
    "\n",
    "# Relevand documentation: \n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html \n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\n",
    "\n",
    "df_minus_controls = clean_df.AMD_ID.nunique()                           # count number of unique elements now that controls were removed \n",
    "\n",
    "print(clean_df_w_controls - df_minus_controls,'control or US domestic samples were removed, leaving now:', df_minus_controls, 'records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "69685a1f-7b0b-4022-86f9-fba123afa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 fastq filename records. Do these match with what is expected?\n",
      "Are all records unique? True\n",
      "This many records are unique 72\n",
      "Filenames with less than 20 characters:\n",
      "18GNMa1A0129PfF1290 has a length of 19\n"
     ]
    }
   ],
   "source": [
    "## QC Check length of new filenames ## \n",
    "\n",
    "print('There are', len(clean_df.AMD_ID), 'fastq filename records. Do these match with what is expected?')  # check number of filename records \n",
    "\n",
    "print('Are all records unique?', clean_df.AMD_ID.is_unique)                                                # check if all records are unique \n",
    "\n",
    "print('This many records are unique',clean_df.AMD_ID.nunique())                                            # count number of unique elements \n",
    "    \n",
    "print('Filenames with less than 20 characters:') \n",
    "\n",
    "for items in clean_df.AMD_ID:\n",
    "    if (len(items)) < 20: print(items, 'has a length of', len(items))                                      # check for any filenames that are less than the expected 20 characters\n",
    "\n",
    "\n",
    "## FIX ANY INCORRECT LENGTHS BEFORE MOVING ON ## \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "fb00822d-11ce-4b0b-a697-d31782193809",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load NMS and NGS team excel documents ## \n",
    "\n",
    "## NMS team document ## \n",
    "NMS_team_data = pd.read_excel (r'NMS results_for Guinea TES 2017-2019_Final 03-08-2021_Final Call.xlsx',  sheet_name='Recurrent samples',header=[0,3])   # read excel file, specify header from row 0 to 3 as it has merged rows and columns\n",
    "\n",
    "## NGS team document ## \n",
    "NGS_team_data = pd.read_excel (r'Guinea Paired Masterfile.xlsx', sheet_name='MS to NGS Sample Naming ',usecols=[\"AMD_ID\",\"CSID\"])                        # read file using only columns AMDID and CSID to remove unwanted columns from reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ca49f5-006f-4025-ab58-1d86a9162009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run quick stats on df ## \n",
    "\n",
    "# skim(NMS_team_data)\n",
    "# skim(NGS_team_data)\n",
    "\n",
    "#print(NGS_team_data.isnull().sum())       # Check for null or NaN values in specific row \n",
    "#print(NMS_team_data.isnull().sum())       # Check for null or NaN values in specific row \n",
    "\n",
    "# Note any missing data and total counts and make sure it won't interfere with merging. \n",
    "# Note the number of availble records for RvR and compare to fastq output records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "0acba913-31a7-43f2-b2bf-47b7f8f4be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge NGS_team data based on AMD ID ## \n",
    "\n",
    "combine_data = clean_df.merge(NGS_team_data,on=\"AMD_ID\")   # merge AMD ID file with NGS team data to add CSID save as combine_data var\n",
    "# combine_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "4c3aa91b-4dd3-4e8e-b28e-4cf6d55a78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up NMS team data ## \n",
    "\n",
    "NMS_team_data.rename({'Unnamed: 31_level_1': 'RvR'}, axis=1, inplace=True)            # rename recurdesdence column to RvR; lists the probabilities that its a recurdesdence vs reinfection; >0.5 = recurdesdence; <0.5 = reinfection; =0.5 = recurdesdence/reinfection \n",
    "NMS_team_data.columns = NMS_team_data.columns.droplevel(0)                            # remove first row of header and keep second as it has two header column\n",
    "NMS_team_data.columns = NMS_team_data.columns.fillna('RvR')                           # fill NAs\n",
    "\n",
    "#skim(NMS_team_data)  # check data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "ae35d4eb-7178-44d7-8bf2-12c1b5626fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge NMS data with NGS data linked by CSID ## \n",
    "\n",
    "combine_data_final = combine_data.merge(NMS_team_data,on=\"CSID\")                 # merge NGS team and NMS team data by CSID and save as new combine_data_final var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "97ad53c2-3c5a-4be4-8174-a03d1e91a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up combined data, keep only relevant element, add RvR calls ## \n",
    "\n",
    "final_output = combine_data_final[['AMD_ID', 'CSID', 'Day 0 or failure','Sample ID', 'Treatment arm','RvR']]          # onlyuse this columns\n",
    "\n",
    "final_output['Molecular classification'] = np.where(final_output['RvR']>0.5, 'Recrudescence', 'Reinfection')          # If value is 0.5 or more, Recrudescence otherwise reinfection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcfd0f-35f6-4d9e-bf84-f47fcbfd67fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "fc8b84df-a175-405b-953a-ce1f3009c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save combined data as new csv ## \n",
    "\n",
    "#final_output.to_csv('Guinea_NCBI_metadata.csv')   # csv file as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "0976b400-66b0-465d-95ce-301fdaa92f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are null records for: \n",
      " AMD_ID                      0\n",
      "CSID                        0\n",
      "Day 0 or failure            0\n",
      "Sample ID                   0\n",
      "Treatment arm               0\n",
      "RvR                         1\n",
      "Molecular classification    0\n",
      "dtype: int64\n",
      "Successfully linked: 71 records out of 72\n"
     ]
    }
   ],
   "source": [
    "## QC for final output ## \n",
    "\n",
    "print('There are null records for: \\n',final_output.isnull().sum())           # Check for null or NaN values in specific row \n",
    "\n",
    "print('Successfully linked:', final_output.AMD_ID.nunique(), 'records out of',clean_df.AMD_ID.nunique())       # Check unique AMD_ID records now = successful links; does it make sense? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab75849-a988-41b7-b65e-745fc4b2a655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49080b-304c-409f-9649-d0f70f553510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
