{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a5a3e9-1b3d-44f4-91d7-d918abd65ae4",
   "metadata": {},
   "source": [
    "### REQUIRED SET UP\n",
    "If you opened this not using a virtual env set up, please read [Virtual Env for python notebooks](https://www.zainrizvi.io/blog/jupyter-notebooks-best-practices-use-virtual-environments/) and restart. Thank you!\n",
    "\n",
    "### Background \n",
    "\n",
    "[NCBI MaRS Bioproject](https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA428490) is used to submit raw fastq files along with associated meta data as soon as possible. NCBI requires that associated meta data (attributes) is submitted with each fastq record. \n",
    "\n",
    "### Code information \n",
    "\n",
    "The code block below links the sample specific meta data (ex. CSID, EPI_ID, Molecular Classification, Day of Treatment, Treatment) to the AMD ID generated by the NGS lab team (AMD ID = name of each fastq file). For more information about the AMD ID, please refer to the MS Teams channel Domestic Surveillance > Files > Sample Naming.  \n",
    "\n",
    "### Required dependencies \n",
    "\n",
    "\n",
    " - [pandas](https://pandas.pydata.org)\n",
    " - [numpy](https://numpy.org)\n",
    " - [glob](https://docs.python.org/3/library/glob.html)\n",
    " - [skimpy](https://pypi.org/project/skimpy/) \n",
    " - [openpyxl](https://openpyxl.readthedocs.io/en/stable/) \n",
    " \n",
    "```python\n",
    "python3 -m pip install --upgrade pip  # upgrade pip \n",
    "python3 -m pip install module_name    # install modules via terminal in current virtual env; if you run into issues, install it system wide. \n",
    "\n",
    "```\n",
    " \n",
    "### Inputs\n",
    "\n",
    "Under one directory\n",
    " - Raw fastq paired files\n",
    "     - Make sure to rename the directory to the specific country (ex. raw reads > Guinea) \n",
    " - Excel files with metadata information (this is provided by the NGS lab and Microsatellites Team) \n",
    "\n",
    "\n",
    " ### Output\n",
    " - csv file with all metadata linked with the AMD ID to be used during the NCBI SRA submission \n",
    "  \n",
    " Note: This code is written for Guinea Paired samples. Please modify the filepaths, filenames, etc for another use case (e.g., country). \n",
    " \n",
    " #### TODO: \n",
    " \n",
    "  #### Activity Name\n",
    " - [ ] Add QC checks (ex. count of ID and elements match) and random cross-match & visual inspect @Dhruvi & Je-Hoon 03-31-2022 \n",
    " - [ ] Review with @ Eldin \n",
    " - [ ] Talk to Lab and NMS team (@ Samaly) and ensure excel format is standardized including naming of files, tabs, etc @Dhruvi 04-01-2022\n",
    " \n",
    "   - Dhruvi: talked with NMS(Samlay) team. The formate of excel sheet is same however they are doing excel sheet name diffenrtly. So evry time we have to change the file name and heeet name to run the code.\n",
    "    \n",
    " #### Completed Activity âœ“\n",
    " - [x] Updated readme, code to make it more explicit and detailed comments @ET 03-31-2022 \n",
    " - [x] Seperated code based on processes and added basic QC sections @ET 03-31-2022 \n",
    " - [x] placeholder \n",
    "\n",
    " #### Task \n",
    " _Template_ \n",
    " \n",
    " - [ ] Task title ~3d #type @name yyyy-mm-dd\n",
    "    - [ ] Sub-task description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88d155d9-435e-4e8f-936d-2ab5126b9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up saved variables; clean slate ## \n",
    "#dir()      # check saved variables \n",
    "#%reset    # this cleares saved variables; use only if there are too many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a525a3fc-2a43-4dd3-9424-504bbf57481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many filename records are unique: 72\n"
     ]
    }
   ],
   "source": [
    "## Import dependencies ## \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimpy import skim\n",
    "\n",
    "## Get fastq filenames ## \n",
    "my_file = [f for f in glob.glob(\"Guinea/*.fastq.gz\")]\n",
    "#my_file = [f for f in glob.glob(\"Guinea/*.fastq.gz\")]                 # use glob to save the files names to my_file variable (var)   \n",
    "clean_filenames = []                                                   # create an empty list called fastq_raw var \n",
    "\n",
    "## Cleaning of filenames ## \n",
    "\n",
    "for doc_name in my_file:                                               # loop through my_file \n",
    "    new_doc_name = doc_name.replace('Guinea/',\"\")                      # remove \"Guinea/\" from filename and save in new_doc_name var \n",
    "    clean_filenames.append(new_doc_name.split(\"_\")[0])                 # split file name by underscore \"_\" and keep 20 digit AMD ID and save as clean_filenames var \n",
    "\n",
    "## Create clean dataframe with cleaned filenames ## \n",
    "\n",
    "clean_df = pd.DataFrame(clean_filenames, columns=[\"AMD_ID\"])           # add column name to data frame called AMD_ID\n",
    "clean_df = clean_df.drop_duplicates()                                  # drop duplicate records since each fastq record is paired (fq1 and fq2) \n",
    "\n",
    "## Check how many unique records ## \n",
    "\n",
    "clean_df_w_controls = clean_df.AMD_ID.nunique()                        # count number of unique elements \n",
    "print('This many filename records are unique:', clean_df_w_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7b0eab3-6b13-4525-b4ba-2091e7c03de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 control or US domestic samples were removed, leaving now: 72 records\n"
     ]
    }
   ],
   "source": [
    "## Remove US or control strains from dataframe ## \n",
    "\n",
    "discard = [\"21US\"]                                                     # provide specific string pattern and save as discard var; discard all domestic samples or control strains \n",
    "\n",
    "clean_df = clean_df[~clean_df.AMD_ID.str.contains('|'.join(discard))]  # test if string pattern or regex is conatined within a string and drop the rows\n",
    "\n",
    "# Relevand documentation: \n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html \n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\n",
    "\n",
    "df_minus_controls = clean_df.AMD_ID.nunique()                           # count number of unique elements now that controls were removed \n",
    "\n",
    "print(clean_df_w_controls - df_minus_controls,'control or US domestic samples were removed, leaving now:', df_minus_controls, 'records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e716404-f6bb-428d-953a-2ff2d850cdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 fastq filename records. Do these match with what is expected?\n",
      "Are all records unique? True\n",
      "This many records are unique 72\n",
      "Filenames with less than 20 characters:\n",
      "18GNMa1A0129PfF1290 has a length of 19\n"
     ]
    }
   ],
   "source": [
    "## QC Check length of new filenames ## \n",
    "\n",
    "print('There are', len(clean_df.AMD_ID), 'fastq filename records. Do these match with what is expected?')  # check number of filename records \n",
    "\n",
    "print('Are all records unique?', clean_df.AMD_ID.is_unique)                                                # check if all records are unique \n",
    "\n",
    "print('This many records are unique',clean_df.AMD_ID.nunique())                                            # count number of unique elements \n",
    "    \n",
    "print('Filenames with less than 20 characters:') \n",
    "\n",
    "for items in clean_df.AMD_ID:\n",
    "    if (len(items)) < 20: print(items, 'has a length of', len(items))                                      # check for any filenames that are less than the expected 20 characters\n",
    "\n",
    "\n",
    "## FIX ANY INCORRECT LENGTHS BEFORE MOVING ON ## \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d2ce5dcf-1f74-48f3-bf26-4b29742a9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## NMS team document ## \n",
    "NMS_team_data = pd.read_excel (r'NMS results_for Guinea TES 2017-2019_Final 03-08-2021_Final Call.xlsx',  sheet_name='Recurrent samples',header=[3])     # read excel file, specify header from row 0 to 3 as it has merged rows and columns\n",
    "\n",
    "## NGS team document ## \n",
    "NGS_team_data = pd.read_excel (r'Guinea Paired Masterfile.xlsx', sheet_name='MS to NGS Sample Naming ',usecols=[\"AMD_ID\",\"CSID\"])                        # read file using only columns AMDID and CSID to remove unwanted columns from reading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2c7d4d5-6895-4e60-bc43-b46ddfcbd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run quick stats on df ## \n",
    "\n",
    "#skim(NMS_team_data)\n",
    "#skim(NGS_team_data)\n",
    "\n",
    "#print(NGS_team_data.isnull().sum())       # Check for null or NaN values in specific row \n",
    "#print(NMS_team_data.isnull().sum())       # Check for null or NaN values in specific row \n",
    "\n",
    "# Note any missing data and total counts and make sure it won't interfere with merging. \n",
    "# Note the number of availble records for RvR and compare to fastq output records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83fdf487-1573-43db-9aee-5a294e9ca080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Merge NGS_team data based on AMD ID ## \n",
    "\n",
    "combine_data = clean_df.merge(NGS_team_data,on=\"AMD_ID\")   # merge AMD ID file with NGS team data to add CSID save as combine_data var\n",
    "# combine_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae351eae-9da4-4a0e-a10b-64bd7a46bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up NMS team data ## \n",
    "\n",
    "NMS_team_data.rename({'Unnamed: 31': 'RvR'}, axis=1, inplace=True)            # rename recurdesdence column to RvR; lists the probabilities that its a recurdesdence vs reinfection; >0.5 = recurdesdence; <0.5 = reinfection; =0.5 = recurdesdence/reinfection \n",
    "NMS_team_data = NMS_team_data.replace(r'^\\s*$', np.nan, regex=True)           # replace the white space cells with nan value                 \n",
    "NMS_team_data[['RvR']] = NMS_team_data[['RvR']].fillna(value=0)               # fill NAs\n",
    "\n",
    "#skim(NMS_team_data)  # check data frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "809225af-0a37-45eb-b2b8-f9cac1cfe6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Merge NMS data with NGS data linked by CSID ## \n",
    "\n",
    "combine_data_final = combine_data.merge(NMS_team_data,on=\"CSID\", how='inner')                 # merge NGS team and NMS team data by CSID and save as new combine_data_final var \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e2035-96ba-4a3e-8b95-ffd5148518d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up combined data, keep only relevant element, add RvR calls ## \n",
    "\n",
    "final_output = combine_data_final[['AMD_ID', 'CSID', 'Day 0 or failure','Sample ID', 'Treatment arm','RvR']]          # onlyuse this columns\n",
    "\n",
    "final_output['Molecular classification'] = np.where(final_output['RvR']>0.5, 'Recrudescence', 'Reinfection')          # If value is 0.5 or more, Recrudescence otherwise reinfection   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81652d6b-ddad-46a3-9b18-1bd174f804cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save combined data as new csv ## \n",
    "\n",
    "final_output.to_csv('Guinea_NCBI_metadata.csv')   # csv file as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "25e43c80-ff24-4048-bc72-e9fe74231afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are null records for: \n",
      " AMD_ID                      0\n",
      "CSID                        0\n",
      "Day 0 or failure            0\n",
      "Sample ID                   0\n",
      "Treatment arm               0\n",
      "RvR                         0\n",
      "Molecular classification    0\n",
      "dtype: int64\n",
      "Successfully linked: 71 records out of 72\n"
     ]
    }
   ],
   "source": [
    "## QC for final output ## \n",
    "\n",
    "print('There are null records for: \\n',final_output.isnull().sum())           # Check for null or NaN values in specific row \n",
    "\n",
    "print('Successfully linked:', final_output.AMD_ID.nunique(), 'records out of',clean_df.AMD_ID.nunique())       # Check unique AMD_ID records now = successful links; does it make sense? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccb33c-5d51-48a0-a6d2-72302622ae92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d4abd-d26e-4f68-b1d0-03b187df06c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
